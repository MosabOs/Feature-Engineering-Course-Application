{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293e6ea7",
   "metadata": {
    "papermill": {
     "duration": 0.00842,
     "end_time": "2025-11-29T18:03:34.937268",
     "exception": false,
     "start_time": "2025-11-29T18:03:34.928848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 1 - Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ff7dd8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:34.957141Z",
     "iopub.status.busy": "2025-11-29T18:03:34.956591Z",
     "iopub.status.idle": "2025-11-29T18:03:40.810890Z",
     "shell.execute_reply": "2025-11-29T18:03:40.809739Z"
    },
    "papermill": {
     "duration": 5.867651,
     "end_time": "2025-11-29T18:03:40.813517",
     "exception": false,
     "start_time": "2025-11-29T18:03:34.945866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/1545505161.py:20: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use(\"seaborn-whitegrid\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings \n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import KFold , cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "# Mute warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e6ad3",
   "metadata": {
    "papermill": {
     "duration": 0.008967,
     "end_time": "2025-11-29T18:03:40.830825",
     "exception": false,
     "start_time": "2025-11-29T18:03:40.821858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing\n",
    "For this comp we need to:\n",
    "- **Load** the data from CSV files\n",
    "- **Clean** the data to fix any errors or inconsistencies\n",
    "- **Encode** the statistical data type (numeric, categorical)\n",
    "- **Impute** any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5925da9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:40.848894Z",
     "iopub.status.busy": "2025-11-29T18:03:40.848379Z",
     "iopub.status.idle": "2025-11-29T18:03:40.854153Z",
     "shell.execute_reply": "2025-11-29T18:03:40.853244Z"
    },
    "papermill": {
     "duration": 0.017095,
     "end_time": "2025-11-29T18:03:40.856104",
     "exception": false,
     "start_time": "2025-11-29T18:03:40.839009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Read data\n",
    "    data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n",
    "    df_train = pd.read_csv(data_dir / \"train.csv\" , index_col=\"Id\")\n",
    "    df_test = pd.read_csv(data_dir / \"test.csv\" , index_col=\"Id\")\n",
    "    # Merge the splits so we can procces them together \n",
    "    df = pd.concat([df_train , df_test])\n",
    "    # PREPROCESSING\n",
    "    df = clean(df)\n",
    "    df = encode(df)\n",
    "    df = impute(df)\n",
    "    # Reform splits\n",
    "    df_train = df.loc[df_train.index , :]\n",
    "    df_test = df.loc[df_test.index , :]\n",
    "    return df_train , df_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3906a8d",
   "metadata": {
    "papermill": {
     "duration": 0.007545,
     "end_time": "2025-11-29T18:03:40.871755",
     "exception": false,
     "start_time": "2025-11-29T18:03:40.864210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Clean Data\n",
    "Some of the categorical features in this dataset have what are apparently typos in their categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd8fbf53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:40.889468Z",
     "iopub.status.busy": "2025-11-29T18:03:40.889123Z",
     "iopub.status.idle": "2025-11-29T18:03:40.958412Z",
     "shell.execute_reply": "2025-11-29T18:03:40.957219Z"
    },
    "papermill": {
     "duration": 0.080371,
     "end_time": "2025-11-29T18:03:40.960403",
     "exception": false,
     "start_time": "2025-11-29T18:03:40.880032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['VinylSd', 'MetalSd', 'Wd Shng', 'HdBoard', 'Plywood', 'Wd Sdng',\n",
       "       'CmentBd', 'BrkFace', 'Stucco', 'AsbShng', 'Brk Cmn', 'ImStucc',\n",
       "       'AsphShn', 'Stone', 'Other', 'CBlock'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n",
    "df = pd.read_csv(data_dir / \"train.csv\", index_col = \"Id\")\n",
    "\n",
    "df.Exterior2nd.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56fa8d9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:40.978402Z",
     "iopub.status.busy": "2025-11-29T18:03:40.978076Z",
     "iopub.status.idle": "2025-11-29T18:03:40.983427Z",
     "shell.execute_reply": "2025-11-29T18:03:40.982539Z"
    },
    "papermill": {
     "duration": 0.016816,
     "end_time": "2025-11-29T18:03:40.985358",
     "exception": false,
     "start_time": "2025-11-29T18:03:40.968542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df[\"Exterior2nd\"] = df[\"Exterior2nd\"].replace({\"Bkr Cmn\":\"BrkComn\"})\n",
    "    # Some Values Of GarageYrBlt are corrupt , so we'll replace them\n",
    "    # with the year the house was built\n",
    "    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].where(df.GarageYrBlt <= 2010, df.YearBuilt)\n",
    "    # Names Beginning with numbers are awkward to work with\n",
    "    df.rename(columns={\n",
    "        \"1stFlrSF\": \"FirstFlrSF\",\n",
    "        \"2ndFlrSF\": \"SecondFlrSF\",\n",
    "        \"3SsnPorch\": \"Threeseasonporch\",\n",
    "    },inplace =True,\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f574d30",
   "metadata": {
    "papermill": {
     "duration": 0.008512,
     "end_time": "2025-11-29T18:03:41.002701",
     "exception": false,
     "start_time": "2025-11-29T18:03:40.994189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encode the Statistical Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65451b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:41.020588Z",
     "iopub.status.busy": "2025-11-29T18:03:41.020217Z",
     "iopub.status.idle": "2025-11-29T18:03:41.026966Z",
     "shell.execute_reply": "2025-11-29T18:03:41.025695Z"
    },
    "papermill": {
     "duration": 0.018171,
     "end_time": "2025-11-29T18:03:41.029359",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.011188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "categorical_feature = df.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "print(categorical_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff60b116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:41.047773Z",
     "iopub.status.busy": "2025-11-29T18:03:41.047394Z",
     "iopub.status.idle": "2025-11-29T18:03:41.056646Z",
     "shell.execute_reply": "2025-11-29T18:03:41.055657Z"
    },
    "papermill": {
     "duration": 0.021155,
     "end_time": "2025-11-29T18:03:41.058769",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.037614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The numeric features are already encoded correctly (`float` for continuous, `int` for discrete), \n",
    "# but the categoricals we'll need to do ourselves.\n",
    "# Note in particular, that the `MSSubClass` feature is\n",
    "# read as an `int` type, but is actually a (nominative) categorical.\n",
    "\n",
    "# The nominative (unordered) categorical features\n",
    "features_nom = [\"MSSubClass\", \"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \"LotConfig\", \"Neighborhood\", \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \"Foundation\", \"Heating\", \"CentralAir\", \"GarageType\", \"MiscFeature\", \"SaleType\", \"SaleCondition\"]\n",
    "\n",
    "\n",
    "\n",
    "# The Ordinal (ordered) categorical Features\n",
    "\n",
    "# Pandas calls the categories \"Levels\"\n",
    "five_levels = [\"Po\", \"Fa\",\"TA\", \"Gd\", \"Ex\"]\n",
    "ten_levels = list(range(10))\n",
    "\n",
    "ordered_levels = {\n",
    "    \"OverallQual\": ten_levels,\n",
    "    \"OverallCond\": ten_levels,\n",
    "    \"ExterQual\": five_levels,\n",
    "    \"ExterCond\": five_levels,\n",
    "    \"BsmtQual\": five_levels,\n",
    "    \"BsmtCond\": five_levels,\n",
    "    \"HeatingQC\": five_levels,\n",
    "    \"KitchenQual\": five_levels,\n",
    "    \"FireplaceQu\": five_levels,\n",
    "    \"GarageQual\": five_levels,\n",
    "    \"GarageCond\": five_levels,\n",
    "    \"PoolQC\": five_levels,\n",
    "    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n",
    "    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n",
    "    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n",
    "    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n",
    "    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n",
    "    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n",
    "    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n",
    "    \"CentralAir\": [\"N\", \"Y\"],\n",
    "    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n",
    "    \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n",
    "}\n",
    "\n",
    "# Add a None Level For Missing Values\n",
    "ordered_levels = {key: [\"None\"] + value for key, value in\n",
    "                 ordered_levels.items()}\n",
    "\n",
    "def encode(df):\n",
    "    # Nominal categories\n",
    "    for name in features_nom:\n",
    "        df[name] = df[name].astype(\"category\")\n",
    "        # Add a None category for missing values\n",
    "        if \"None\" not in df[name].cat.categories:\n",
    "            df[name] = df[name].cat.add_categories(\"None\")\n",
    "    # Ordinal categroies\n",
    "    for name , levels in ordered_levels.items():\n",
    "        df[name] = df[name].astype(CategoricalDtype(levels,\n",
    "                                                   ordered=True))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ff361",
   "metadata": {
    "papermill": {
     "duration": 0.007601,
     "end_time": "2025-11-29T18:03:41.074401",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.066800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Handle Missing Values \n",
    "We'll impute 0 for missing numeric values and \"None\" for missing categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1742e6c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:41.092397Z",
     "iopub.status.busy": "2025-11-29T18:03:41.091994Z",
     "iopub.status.idle": "2025-11-29T18:03:41.097113Z",
     "shell.execute_reply": "2025-11-29T18:03:41.096060Z"
    },
    "papermill": {
     "duration": 0.016668,
     "end_time": "2025-11-29T18:03:41.099225",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.082557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def impute(df):\n",
    "    for name in df.select_dtypes(\"number\"):\n",
    "        df[name] = df[name].fillna(0)\n",
    "    for name in df.select_dtypes(\"category\"):\n",
    "        df[name] = df[name].fillna(\"None\")\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e8a54",
   "metadata": {
    "papermill": {
     "duration": 0.007659,
     "end_time": "2025-11-29T18:03:41.114896",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.107237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data\n",
    "And now we can call the data loader and get the processed data splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "008c4f13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:41.133037Z",
     "iopub.status.busy": "2025-11-29T18:03:41.132137Z",
     "iopub.status.idle": "2025-11-29T18:03:41.241055Z",
     "shell.execute_reply": "2025-11-29T18:03:41.240284Z"
    },
    "papermill": {
     "duration": 0.120607,
     "end_time": "2025-11-29T18:03:41.243445",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.122838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train , df_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc9d31",
   "metadata": {
    "papermill": {
     "duration": 0.007726,
     "end_time": "2025-11-29T18:03:41.259284",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.251558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " Notice that df_test is missing values for SalePrice. (NAs were willed with 0's in the imputation step.)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1577f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:41.277138Z",
     "iopub.status.busy": "2025-11-29T18:03:41.276307Z",
     "iopub.status.idle": "2025-11-29T18:03:41.384925Z",
     "shell.execute_reply": "2025-11-29T18:03:41.383368Z"
    },
    "papermill": {
     "duration": 0.119573,
     "end_time": "2025-11-29T18:03:41.386872",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.267299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                     \n",
       "1            60       RL         65.0     8450   Pave  None      Reg   \n",
       "2            20       RL         80.0     9600   Pave  None      Reg   \n",
       "3            60       RL         68.0    11250   Pave  None      IR1   \n",
       "4            70       RL         60.0     9550   Pave  None      IR1   \n",
       "5            60       RL         84.0    14260   Pave  None      IR1   \n",
       "...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1456         60       RL         62.0     7917   Pave  None      Reg   \n",
       "1457         20       RL         85.0    13175   Pave  None      Reg   \n",
       "1458         70       RL         66.0     9042   Pave  None      Reg   \n",
       "1459         20       RL         68.0     9717   Pave  None      Reg   \n",
       "1460         20       RL         75.0     9937   Pave  None      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
       "Id                                    ...                                      \n",
       "1            Lvl    AllPub    Inside  ...        0   None   None        None   \n",
       "2            Lvl    AllPub       FR2  ...        0   None   None        None   \n",
       "3            Lvl    AllPub    Inside  ...        0   None   None        None   \n",
       "4            Lvl    AllPub    Corner  ...        0   None   None        None   \n",
       "5            Lvl    AllPub       FR2  ...        0   None   None        None   \n",
       "...          ...       ...       ...  ...      ...    ...    ...         ...   \n",
       "1456         Lvl    AllPub    Inside  ...        0   None   None        None   \n",
       "1457         Lvl    AllPub    Inside  ...        0   None  MnPrv        None   \n",
       "1458         Lvl    AllPub    Inside  ...        0   None  GdPrv        Shed   \n",
       "1459         Lvl    AllPub    Inside  ...        0   None   None        None   \n",
       "1460         Lvl    AllPub    Inside  ...        0   None   None        None   \n",
       "\n",
       "     MiscVal MoSold YrSold SaleType  SaleCondition  SalePrice  \n",
       "Id                                                             \n",
       "1          0      2   2008       WD         Normal   208500.0  \n",
       "2          0      5   2007       WD         Normal   181500.0  \n",
       "3          0      9   2008       WD         Normal   223500.0  \n",
       "4          0      2   2006       WD        Abnorml   140000.0  \n",
       "5          0     12   2008       WD         Normal   250000.0  \n",
       "...      ...    ...    ...      ...            ...        ...  \n",
       "1456       0      8   2007       WD         Normal   175000.0  \n",
       "1457       0      2   2010       WD         Normal   210000.0  \n",
       "1458    2500      5   2010       WD         Normal   266500.0  \n",
       "1459       0      4   2010       WD         Normal   142125.0  \n",
       "1460       0      6   2008       WD         Normal   147500.0  \n",
       "\n",
       "[1460 rows x 80 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                     \n",
       "1461         20       RH         80.0    11622   Pave  None      Reg   \n",
       "1462         20       RL         81.0    14267   Pave  None      IR1   \n",
       "1463         60       RL         74.0    13830   Pave  None      IR1   \n",
       "1464         60       RL         78.0     9978   Pave  None      IR1   \n",
       "1465        120       RL         43.0     5005   Pave  None      IR1   \n",
       "...         ...      ...          ...      ...    ...   ...      ...   \n",
       "2915        160       RM         21.0     1936   Pave  None      Reg   \n",
       "2916        160       RM         21.0     1894   Pave  None      Reg   \n",
       "2917         20       RL        160.0    20000   Pave  None      Reg   \n",
       "2918         85       RL         62.0    10441   Pave  None      Reg   \n",
       "2919         60       RL         74.0     9627   Pave  None      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
       "Id                                    ...                                      \n",
       "1461         Lvl    AllPub    Inside  ...        0   None  MnPrv        None   \n",
       "1462         Lvl    AllPub    Corner  ...        0   None   None        Gar2   \n",
       "1463         Lvl    AllPub    Inside  ...        0   None  MnPrv        None   \n",
       "1464         Lvl    AllPub    Inside  ...        0   None   None        None   \n",
       "1465         HLS    AllPub    Inside  ...        0   None   None        None   \n",
       "...          ...       ...       ...  ...      ...    ...    ...         ...   \n",
       "2915         Lvl    AllPub    Inside  ...        0   None   None        None   \n",
       "2916         Lvl    AllPub    Inside  ...        0   None   None        None   \n",
       "2917         Lvl    AllPub    Inside  ...        0   None   None        None   \n",
       "2918         Lvl    AllPub    Inside  ...        0   None  MnPrv        Shed   \n",
       "2919         Lvl    AllPub    Inside  ...        0   None   None        None   \n",
       "\n",
       "     MiscVal MoSold YrSold SaleType  SaleCondition  SalePrice  \n",
       "Id                                                             \n",
       "1461       0      6   2010       WD         Normal        0.0  \n",
       "1462   12500      6   2010       WD         Normal        0.0  \n",
       "1463       0      3   2010       WD         Normal        0.0  \n",
       "1464       0      6   2010       WD         Normal        0.0  \n",
       "1465       0      1   2010       WD         Normal        0.0  \n",
       "...      ...    ...    ...      ...            ...        ...  \n",
       "2915       0      6   2006       WD         Normal        0.0  \n",
       "2916       0      4   2006       WD        Abnorml        0.0  \n",
       "2917       0      9   2006       WD        Abnorml        0.0  \n",
       "2918     700      7   2006       WD         Normal        0.0  \n",
       "2919       0     11   2006       WD         Normal        0.0  \n",
       "\n",
       "[1459 rows x 80 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1460 entries, 1 to 1460\n",
      "Data columns (total 80 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   MSSubClass        1460 non-null   category\n",
      " 1   MSZoning          1460 non-null   category\n",
      " 2   LotFrontage       1460 non-null   float64 \n",
      " 3   LotArea           1460 non-null   int64   \n",
      " 4   Street            1460 non-null   category\n",
      " 5   Alley             1460 non-null   category\n",
      " 6   LotShape          1460 non-null   category\n",
      " 7   LandContour       1460 non-null   category\n",
      " 8   Utilities         1460 non-null   category\n",
      " 9   LotConfig         1460 non-null   category\n",
      " 10  LandSlope         1460 non-null   category\n",
      " 11  Neighborhood      1460 non-null   category\n",
      " 12  Condition1        1460 non-null   category\n",
      " 13  Condition2        1460 non-null   category\n",
      " 14  BldgType          1460 non-null   category\n",
      " 15  HouseStyle        1460 non-null   category\n",
      " 16  OverallQual       1460 non-null   category\n",
      " 17  OverallCond       1460 non-null   category\n",
      " 18  YearBuilt         1460 non-null   int64   \n",
      " 19  YearRemodAdd      1460 non-null   int64   \n",
      " 20  RoofStyle         1460 non-null   category\n",
      " 21  RoofMatl          1460 non-null   category\n",
      " 22  Exterior1st       1460 non-null   category\n",
      " 23  Exterior2nd       1460 non-null   category\n",
      " 24  MasVnrType        1460 non-null   category\n",
      " 25  MasVnrArea        1460 non-null   float64 \n",
      " 26  ExterQual         1460 non-null   category\n",
      " 27  ExterCond         1460 non-null   category\n",
      " 28  Foundation        1460 non-null   category\n",
      " 29  BsmtQual          1460 non-null   category\n",
      " 30  BsmtCond          1460 non-null   category\n",
      " 31  BsmtExposure      1460 non-null   category\n",
      " 32  BsmtFinType1      1460 non-null   category\n",
      " 33  BsmtFinSF1        1460 non-null   float64 \n",
      " 34  BsmtFinType2      1460 non-null   category\n",
      " 35  BsmtFinSF2        1460 non-null   float64 \n",
      " 36  BsmtUnfSF         1460 non-null   float64 \n",
      " 37  TotalBsmtSF       1460 non-null   float64 \n",
      " 38  Heating           1460 non-null   category\n",
      " 39  HeatingQC         1460 non-null   category\n",
      " 40  CentralAir        1460 non-null   category\n",
      " 41  Electrical        1460 non-null   category\n",
      " 42  FirstFlrSF        1460 non-null   int64   \n",
      " 43  SecondFlrSF       1460 non-null   int64   \n",
      " 44  LowQualFinSF      1460 non-null   int64   \n",
      " 45  GrLivArea         1460 non-null   int64   \n",
      " 46  BsmtFullBath      1460 non-null   float64 \n",
      " 47  BsmtHalfBath      1460 non-null   float64 \n",
      " 48  FullBath          1460 non-null   int64   \n",
      " 49  HalfBath          1460 non-null   int64   \n",
      " 50  BedroomAbvGr      1460 non-null   int64   \n",
      " 51  KitchenAbvGr      1460 non-null   int64   \n",
      " 52  KitchenQual       1460 non-null   category\n",
      " 53  TotRmsAbvGrd      1460 non-null   int64   \n",
      " 54  Functional        1460 non-null   category\n",
      " 55  Fireplaces        1460 non-null   int64   \n",
      " 56  FireplaceQu       1460 non-null   category\n",
      " 57  GarageType        1460 non-null   category\n",
      " 58  GarageYrBlt       1460 non-null   float64 \n",
      " 59  GarageFinish      1460 non-null   category\n",
      " 60  GarageCars        1460 non-null   float64 \n",
      " 61  GarageArea        1460 non-null   float64 \n",
      " 62  GarageQual        1460 non-null   category\n",
      " 63  GarageCond        1460 non-null   category\n",
      " 64  PavedDrive        1460 non-null   category\n",
      " 65  WoodDeckSF        1460 non-null   int64   \n",
      " 66  OpenPorchSF       1460 non-null   int64   \n",
      " 67  EnclosedPorch     1460 non-null   int64   \n",
      " 68  Threeseasonporch  1460 non-null   int64   \n",
      " 69  ScreenPorch       1460 non-null   int64   \n",
      " 70  PoolArea          1460 non-null   int64   \n",
      " 71  PoolQC            1460 non-null   category\n",
      " 72  Fence             1460 non-null   category\n",
      " 73  MiscFeature       1460 non-null   category\n",
      " 74  MiscVal           1460 non-null   int64   \n",
      " 75  MoSold            1460 non-null   int64   \n",
      " 76  YrSold            1460 non-null   int64   \n",
      " 77  SaleType          1460 non-null   category\n",
      " 78  SaleCondition     1460 non-null   category\n",
      " 79  SalePrice         1460 non-null   float64 \n",
      "dtypes: category(46), float64(12), int64(22)\n",
      "memory usage: 478.9 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1459 entries, 1461 to 2919\n",
      "Data columns (total 80 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   MSSubClass        1459 non-null   category\n",
      " 1   MSZoning          1459 non-null   category\n",
      " 2   LotFrontage       1459 non-null   float64 \n",
      " 3   LotArea           1459 non-null   int64   \n",
      " 4   Street            1459 non-null   category\n",
      " 5   Alley             1459 non-null   category\n",
      " 6   LotShape          1459 non-null   category\n",
      " 7   LandContour       1459 non-null   category\n",
      " 8   Utilities         1459 non-null   category\n",
      " 9   LotConfig         1459 non-null   category\n",
      " 10  LandSlope         1459 non-null   category\n",
      " 11  Neighborhood      1459 non-null   category\n",
      " 12  Condition1        1459 non-null   category\n",
      " 13  Condition2        1459 non-null   category\n",
      " 14  BldgType          1459 non-null   category\n",
      " 15  HouseStyle        1459 non-null   category\n",
      " 16  OverallQual       1459 non-null   category\n",
      " 17  OverallCond       1459 non-null   category\n",
      " 18  YearBuilt         1459 non-null   int64   \n",
      " 19  YearRemodAdd      1459 non-null   int64   \n",
      " 20  RoofStyle         1459 non-null   category\n",
      " 21  RoofMatl          1459 non-null   category\n",
      " 22  Exterior1st       1459 non-null   category\n",
      " 23  Exterior2nd       1459 non-null   category\n",
      " 24  MasVnrType        1459 non-null   category\n",
      " 25  MasVnrArea        1459 non-null   float64 \n",
      " 26  ExterQual         1459 non-null   category\n",
      " 27  ExterCond         1459 non-null   category\n",
      " 28  Foundation        1459 non-null   category\n",
      " 29  BsmtQual          1459 non-null   category\n",
      " 30  BsmtCond          1459 non-null   category\n",
      " 31  BsmtExposure      1459 non-null   category\n",
      " 32  BsmtFinType1      1459 non-null   category\n",
      " 33  BsmtFinSF1        1459 non-null   float64 \n",
      " 34  BsmtFinType2      1459 non-null   category\n",
      " 35  BsmtFinSF2        1459 non-null   float64 \n",
      " 36  BsmtUnfSF         1459 non-null   float64 \n",
      " 37  TotalBsmtSF       1459 non-null   float64 \n",
      " 38  Heating           1459 non-null   category\n",
      " 39  HeatingQC         1459 non-null   category\n",
      " 40  CentralAir        1459 non-null   category\n",
      " 41  Electrical        1459 non-null   category\n",
      " 42  FirstFlrSF        1459 non-null   int64   \n",
      " 43  SecondFlrSF       1459 non-null   int64   \n",
      " 44  LowQualFinSF      1459 non-null   int64   \n",
      " 45  GrLivArea         1459 non-null   int64   \n",
      " 46  BsmtFullBath      1459 non-null   float64 \n",
      " 47  BsmtHalfBath      1459 non-null   float64 \n",
      " 48  FullBath          1459 non-null   int64   \n",
      " 49  HalfBath          1459 non-null   int64   \n",
      " 50  BedroomAbvGr      1459 non-null   int64   \n",
      " 51  KitchenAbvGr      1459 non-null   int64   \n",
      " 52  KitchenQual       1459 non-null   category\n",
      " 53  TotRmsAbvGrd      1459 non-null   int64   \n",
      " 54  Functional        1459 non-null   category\n",
      " 55  Fireplaces        1459 non-null   int64   \n",
      " 56  FireplaceQu       1459 non-null   category\n",
      " 57  GarageType        1459 non-null   category\n",
      " 58  GarageYrBlt       1459 non-null   float64 \n",
      " 59  GarageFinish      1459 non-null   category\n",
      " 60  GarageCars        1459 non-null   float64 \n",
      " 61  GarageArea        1459 non-null   float64 \n",
      " 62  GarageQual        1459 non-null   category\n",
      " 63  GarageCond        1459 non-null   category\n",
      " 64  PavedDrive        1459 non-null   category\n",
      " 65  WoodDeckSF        1459 non-null   int64   \n",
      " 66  OpenPorchSF       1459 non-null   int64   \n",
      " 67  EnclosedPorch     1459 non-null   int64   \n",
      " 68  Threeseasonporch  1459 non-null   int64   \n",
      " 69  ScreenPorch       1459 non-null   int64   \n",
      " 70  PoolArea          1459 non-null   int64   \n",
      " 71  PoolQC            1459 non-null   category\n",
      " 72  Fence             1459 non-null   category\n",
      " 73  MiscFeature       1459 non-null   category\n",
      " 74  MiscVal           1459 non-null   int64   \n",
      " 75  MoSold            1459 non-null   int64   \n",
      " 76  YrSold            1459 non-null   int64   \n",
      " 77  SaleType          1459 non-null   category\n",
      " 78  SaleCondition     1459 non-null   category\n",
      " 79  SalePrice         1459 non-null   float64 \n",
      "dtypes: category(46), float64(12), int64(22)\n",
      "memory usage: 478.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Peek at the values\n",
    "display(df_train)\n",
    "display(df_test)\n",
    "\n",
    "# Display information about dtypes and missing values\n",
    "display(df_train.info())\n",
    "display(df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f06de22",
   "metadata": {
    "papermill": {
     "duration": 0.009368,
     "end_time": "2025-11-29T18:03:41.405583",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.396215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Establish Baseline\n",
    "establish a baseline score to judge our feature engineering against.\n",
    "\n",
    "- **Label encoding for categoricals** \n",
    "- **Label encoding is good for XGBoost and RandomForest,** \n",
    "- **but one-hot would be better for models like Lasso or Ridge.** \n",
    "- **The `cat.codes` attribute holds the category levels.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc308a59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:41.425892Z",
     "iopub.status.busy": "2025-11-29T18:03:41.425371Z",
     "iopub.status.idle": "2025-11-29T18:03:41.431599Z",
     "shell.execute_reply": "2025-11-29T18:03:41.430400Z"
    },
    "papermill": {
     "duration": 0.018845,
     "end_time": "2025-11-29T18:03:41.433695",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.414850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_dataset(X , y , model=XGBRegressor()):\n",
    "    # Label encoding for categoricals\n",
    "    \n",
    "    # Label encoding is good for XGBoost and RandomForest , but one-hot\n",
    "    # Would be better for models like Lasso or Ridge. the 'cat.codes'\n",
    "    # attributes holds the category levels.\n",
    "    for colname in X.select_dtypes([\"category\"]):\n",
    "        X[colname] = X[colname].cat.codes\n",
    "    # Metric for Housing Competition is RMSLE (Root Mean Squared Log Error)\n",
    "    log_y = np.log(y)\n",
    "    score = cross_val_score(\n",
    "        model, X , log_y , cv=5 , scoring=\"neg_mean_squared_error\",\n",
    "    )\n",
    "    score = -1 * score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6744c9e6",
   "metadata": {
    "papermill": {
     "duration": 0.008993,
     "end_time": "2025-11-29T18:03:41.451808",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.442815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can reuse this scoring function anytime we want to try out a new feature set. We'll run it now on the processed data with no additional features and get a baseline score:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e5b4546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:41.472203Z",
     "iopub.status.busy": "2025-11-29T18:03:41.471867Z",
     "iopub.status.idle": "2025-11-29T18:03:43.518693Z",
     "shell.execute_reply": "2025-11-29T18:03:43.517534Z"
    },
    "papermill": {
     "duration": 2.060292,
     "end_time": "2025-11-29T18:03:43.521480",
     "exception": false,
     "start_time": "2025-11-29T18:03:41.461188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline score: 0.14387 RSMLE\n"
     ]
    }
   ],
   "source": [
    "X = df_train.copy()\n",
    "y = X.pop(\"SalePrice\")\n",
    "\n",
    "baseline_score = score_dataset(X ,y)\n",
    "print(f\"Baseline score: {baseline_score:.5f} RSMLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41815a0",
   "metadata": {
    "papermill": {
     "duration": 0.008941,
     "end_time": "2025-11-29T18:03:43.539693",
     "exception": false,
     "start_time": "2025-11-29T18:03:43.530752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 2 - Feature Utility Scores\n",
    "In Feature Engineering Course Lesson 2 we saw how to use mutual information to compute a  *utility score* for a feature, giving you an indication of how much potential the feature has. This hidden cell defines the two utility functions we used, `make_mi_scores` and `plot_mi_scores`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe4d30b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:43.560878Z",
     "iopub.status.busy": "2025-11-29T18:03:43.559947Z",
     "iopub.status.idle": "2025-11-29T18:03:43.566728Z",
     "shell.execute_reply": "2025-11-29T18:03:43.565817Z"
    },
    "papermill": {
     "duration": 0.019306,
     "end_time": "2025-11-29T18:03:43.568650",
     "exception": false,
     "start_time": "2025-11-29T18:03:43.549344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    for colname in X.select_dtypes([\"object\",\"category\"]):\n",
    "        X[colname],_ = X[colname].factorize()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_regression(X ,y, discrete_features =discrete_features , random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores , name=\"MI Scores\", index = X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width , scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50621589",
   "metadata": {
    "papermill": {
     "duration": 0.00886,
     "end_time": "2025-11-29T18:03:43.586654",
     "exception": false,
     "start_time": "2025-11-29T18:03:43.577794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "look at our feature scores again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe26d0d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:43.606296Z",
     "iopub.status.busy": "2025-11-29T18:03:43.605954Z",
     "iopub.status.idle": "2025-11-29T18:03:45.779898Z",
     "shell.execute_reply": "2025-11-29T18:03:45.778836Z"
    },
    "papermill": {
     "duration": 2.186036,
     "end_time": "2025-11-29T18:03:45.781915",
     "exception": false,
     "start_time": "2025-11-29T18:03:43.595879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverallQual     0.571457\n",
       "Neighborhood    0.526220\n",
       "GrLivArea       0.430395\n",
       "YearBuilt       0.407974\n",
       "LotArea         0.394468\n",
       "                  ...   \n",
       "PoolQC          0.000000\n",
       "MiscFeature     0.000000\n",
       "MiscVal         0.000000\n",
       "MoSold          0.000000\n",
       "YrSold          0.000000\n",
       "Name: MI Scores, Length: 79, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_train.copy()\n",
    "y = X.pop(\"SalePrice\")\n",
    "\n",
    "mi_scores = make_mi_scores(X,y)\n",
    "mi_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605869d7",
   "metadata": {
    "papermill": {
     "duration": 0.009229,
     "end_time": "2025-11-29T18:03:45.801133",
     "exception": false,
     "start_time": "2025-11-29T18:03:45.791904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that we have a number of features that are highly informative and also some that don't seem to be informative at all (at least by themselves). As we learn in  Feature Engineering Course Tutorial 2, the top scoring features will usually pay-off the most during feature development, so it could be a good idea to focus our efforts on those. On the other hand, training on uninformative features can lead to overfitting. So, the features with 0.0 scores we'll drop entirely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb9885d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:45.821061Z",
     "iopub.status.busy": "2025-11-29T18:03:45.820710Z",
     "iopub.status.idle": "2025-11-29T18:03:45.825307Z",
     "shell.execute_reply": "2025-11-29T18:03:45.824270Z"
    },
    "papermill": {
     "duration": 0.017164,
     "end_time": "2025-11-29T18:03:45.827437",
     "exception": false,
     "start_time": "2025-11-29T18:03:45.810273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_uninformative(df , mi_scores):\n",
    "    return df.loc[: ,mi_scores > 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9aaac6",
   "metadata": {
    "papermill": {
     "duration": 0.009023,
     "end_time": "2025-11-29T18:03:45.846393",
     "exception": false,
     "start_time": "2025-11-29T18:03:45.837370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Removing them does lead to a modest performance gain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d801bee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:45.866646Z",
     "iopub.status.busy": "2025-11-29T18:03:45.866300Z",
     "iopub.status.idle": "2025-11-29T18:03:47.648779Z",
     "shell.execute_reply": "2025-11-29T18:03:47.647919Z"
    },
    "papermill": {
     "duration": 1.796157,
     "end_time": "2025-11-29T18:03:47.652159",
     "exception": false,
     "start_time": "2025-11-29T18:03:45.856002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1441513588582852"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_train.copy()\n",
    "y = X.pop(\"SalePrice\")\n",
    "X = drop_uninformative(X , mi_scores)\n",
    "\n",
    "score_dataset(X , y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b984d4b",
   "metadata": {
    "papermill": {
     "duration": 0.010667,
     "end_time": "2025-11-29T18:03:47.672160",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.661493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> **Later, we'll add the drop_uninformative function to our feature-creation pipeline.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a525bfd",
   "metadata": {
    "papermill": {
     "duration": 0.009162,
     "end_time": "2025-11-29T18:03:47.690703",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.681541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Step 3 - Create Features #\n",
    "\n",
    "Now we'll start developing our feature set.\n",
    "\n",
    "To make our feature engineering workflow more modular, we'll define a function that will take a prepared dataframe and pass it through a pipeline of transformations to get the final feature set. It will look something like this:\n",
    "\n",
    "```\n",
    "def create_features(df):\n",
    "    X = df.copy()\n",
    "    y = X.pop(\"SalePrice\")\n",
    "    X = X.join(create_features_1(X))\n",
    "    X = X.join(create_features_2(X))\n",
    "    X = X.join(create_features_3(X))\n",
    "    # ...\n",
    "    return X\n",
    "```\n",
    "\n",
    "Let's go ahead and define one transformation now, a [label encoding](https://www.kaggle.com/alexisbcook/categorical-variables) for the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12848b30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:47.710929Z",
     "iopub.status.busy": "2025-11-29T18:03:47.710331Z",
     "iopub.status.idle": "2025-11-29T18:03:47.715435Z",
     "shell.execute_reply": "2025-11-29T18:03:47.714303Z"
    },
    "papermill": {
     "duration": 0.017855,
     "end_time": "2025-11-29T18:03:47.717848",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.699993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_encode(df):\n",
    "    X = df.copy()\n",
    "    for colname in X.select_dtypes([\"category\"]):\n",
    "        X[colname] = X[colname].cat.codes\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf982e90",
   "metadata": {
    "papermill": {
     "duration": 0.009123,
     "end_time": "2025-11-29T18:03:47.736851",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.727728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A label encoding is okay for any kind of categorical feature when we're using a tree-ensemble like XGBoost, even for unordered categories. If we wanted to try a linear regression model (also popular in this competition), we would instead want to use a one-hot encoding, especially for the features with unordered categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335ce60",
   "metadata": {
    "papermill": {
     "duration": 0.009407,
     "end_time": "2025-11-29T18:03:47.755525",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.746118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Features with Pandas ##\n",
    "\n",
    "This cell reproduces the work Feature Engineering Course Exercise 3, where we applied strategies for creating features in Pandas. Modify or add to these functions to try out other feature combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "825841b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:47.775409Z",
     "iopub.status.busy": "2025-11-29T18:03:47.775074Z",
     "iopub.status.idle": "2025-11-29T18:03:47.782408Z",
     "shell.execute_reply": "2025-11-29T18:03:47.781472Z"
    },
    "papermill": {
     "duration": 0.019541,
     "end_time": "2025-11-29T18:03:47.784313",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.764772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mathematical_transforms(df):\n",
    "    X = pd.DataFrame() # dataframe to hold new features\n",
    "    X[\"LivLotRatio\"] = df.GrLivArea / df.LotArea\n",
    "    X[\"Spaciousness\"] = (df.FirstFlrSF + df.SecondFlrSF) / df.TotRmsAbvGrd\n",
    "    # This feature ended up not helping performance\n",
    "    # X[\"TotalOutsideSF\"] = \\\n",
    "    #     df.WoodDeckSF + df.OpenPorchSF + df.EnclosedPorch + \\\n",
    "    #     df.Threeseasonporch + df.ScreenPorch\n",
    "    return X\n",
    "def interactions(df):\n",
    "    X = pd.get_dummies(df.BldgType , prefix=\"Bldg\")\n",
    "    X = X.mul(df.GrLivArea , axis=0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def counts(df):\n",
    "    X = pd.DataFrame()\n",
    "    X[\"PorchTypes\"] = df[[\n",
    "        \"WoodDeckSF\",\n",
    "        \"OpenPorchSF\",\n",
    "        \"EnclosedPorch\",\n",
    "        \"Threeseasonporch\",\n",
    "        \"ScreenPorch\",\n",
    "    ]].gt(0.0).sum(axis=1)\n",
    "    return X\n",
    "\n",
    "def break_down(df):\n",
    "    X = pd.DataFrame()\n",
    "    X[\"MSClass\"] = df.MSSubClass.str.split(\"_\", n=1 , expand=True)[0]\n",
    "    return X\n",
    "\n",
    "def group_transforms(df):\n",
    "    X = pd.DataFrame()\n",
    "    X[\"MedNhbdArea\"] = df.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34987229",
   "metadata": {
    "papermill": {
     "duration": 0.008971,
     "end_time": "2025-11-29T18:03:47.802945",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.793974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here are some ideas for other transforms you could explore:\n",
    "- Interactions between the quality `Qual` and condition `Cond` features. `OverallQual`, for instance, was a high-scoring feature. You could try combining it with `OverallCond` by converting both to integer type and taking a product.\n",
    "- Square roots of area features. This would convert units of square feet to just feet.\n",
    "- Logarithms of numeric features. If a feature has a skewed distribution, applying a logarithm can help normalize it.\n",
    "- Interactions between numeric and categorical features that describe the same thing. You could look at interactions between `BsmtQual` and `TotalBsmtSF`, for instance.\n",
    "- Other group statistics in `Neighboorhood`. We did the median of `GrLivArea`. Looking at `mean`, `std`, or `count` could be interesting. You could also try combining the group statistics with other features. Maybe the *difference* of `GrLivArea` and the median is important?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe831754",
   "metadata": {
    "papermill": {
     "duration": 0.008957,
     "end_time": "2025-11-29T18:03:47.821056",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.812099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## k-Means Clustering ##\n",
    "\n",
    "The first unsupervised algorithm we used to create features was k-means clustering. We saw that we could either use the cluster labels as a feature (a column with `0, 1, 2, ...`) or we could use the *distance* of the observations to each cluster. We saw how these features can sometimes be effective at untangling complicated spatial relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7eae8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:47.841062Z",
     "iopub.status.busy": "2025-11-29T18:03:47.840757Z",
     "iopub.status.idle": "2025-11-29T18:03:47.847751Z",
     "shell.execute_reply": "2025-11-29T18:03:47.846768Z"
    },
    "papermill": {
     "duration": 0.019596,
     "end_time": "2025-11-29T18:03:47.849755",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.830159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_features = [\n",
    "    \"LotArea\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"FirstFlrSF\",\n",
    "    \"SecondFlrSF\",\n",
    "    \"GrLivArea\",\n",
    "]\n",
    "\n",
    "def cluster_labels(df , features , n_clusters=20):\n",
    "    X = df.copy()\n",
    "    X_scaled = X.loc[: , features]\n",
    "    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n",
    "    kmeans = KMeans(n_clusters=n_clusters , n_init=50 , random_state=0)\n",
    "    X_new = pd.DataFrame()\n",
    "    X_new[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n",
    "    return X_new\n",
    "\n",
    "def cluster_distance(df , features , n_clusters=20):\n",
    "    X= df.copy()\n",
    "    X_scaled = X.loc[: , features]\n",
    "    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n",
    "    kmeans = KMeans(n_clusters=20 , n_init=50 , random_state=0)\n",
    "    X_cd = kmeans.fit_transform(X_scaled)\n",
    "    # Label features and join to dataset\n",
    "    X_cd = pd.DataFrame(\n",
    "        X_cd , columns =[f\"Centroid_{i}\" for i in range(X_cd.shape[1])]\n",
    "    )\n",
    "    return X_cd\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e6f1fb",
   "metadata": {
    "papermill": {
     "duration": 0.009232,
     "end_time": "2025-11-29T18:03:47.868597",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.859365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Principal Component Analysis ##\n",
    "\n",
    "PCA was the second unsupervised model we used for feature creation. We saw how it could be used to decompose the variational structure in the data. The PCA algorithm gave us *loadings* which described each component of variation, and also the *components* which were the transformed datapoints. The loadings can suggest features to create and the components we can use as features directly.\n",
    "\n",
    "Here are the utility functions from the PCA lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cc5675c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:47.888533Z",
     "iopub.status.busy": "2025-11-29T18:03:47.888168Z",
     "iopub.status.idle": "2025-11-29T18:03:47.896134Z",
     "shell.execute_reply": "2025-11-29T18:03:47.895101Z"
    },
    "papermill": {
     "duration": 0.020201,
     "end_time": "2025-11-29T18:03:47.898067",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.877866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_pca(X , standardize=True):\n",
    "    # Standardize\n",
    "    if standardize:\n",
    "        X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # Create Principal components\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    # Convert to dataframe\n",
    "    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "    # Createw loadings\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T , # transpose the matrix of loadings\n",
    "        columns =component_names , # So the columns are the principal components\n",
    "        index = X.columns, # and the rows are the original features\n",
    "    )\n",
    "    return pca, X_pca , loadings\n",
    "\n",
    "def plot_variance(pca , width=8 , dpi=100):\n",
    "    #Create figure\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    n = pca.n_components_\n",
    "    grid = np.arange(1 , n + 1)\n",
    "    # Explained Variance\n",
    "    evr = pca.explained_variance_ratio_\n",
    "    axs[0].bar(grid , evr)\n",
    "    axis[0].set(\n",
    "        xlabel=\"Components\" , title=\"% Explained Variance\", ylim=(0.0 , 1.0)\n",
    "    )\n",
    "    # Cumulative Variance\n",
    "    cv = np.cumsum(evr)\n",
    "    axs[1].plot(np.r_[0 , grid], np.r_[0, cv], \"o-\")\n",
    "    axs[1].set(\n",
    "        xLabel=\"Component\" , title=\"% Cumulative Variance\", ylim=(0.0 , 1.0)\n",
    "    )\n",
    "    # Set up figure\n",
    "    fig.set(figwidth=8 , dpi =100)\n",
    "    return axs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68c1db",
   "metadata": {
    "papermill": {
     "duration": 0.009213,
     "end_time": "2025-11-29T18:03:47.916900",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.907687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And here are transforms that produce the features from Feature Engineering Course the Exercise 5. we might want to change these if we came up with a different answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "943f7559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:47.936909Z",
     "iopub.status.busy": "2025-11-29T18:03:47.936558Z",
     "iopub.status.idle": "2025-11-29T18:03:47.941914Z",
     "shell.execute_reply": "2025-11-29T18:03:47.941006Z"
    },
    "papermill": {
     "duration": 0.017628,
     "end_time": "2025-11-29T18:03:47.943856",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.926228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pca_inspired(df):\n",
    "    X = pd.DataFrame()\n",
    "    X[\"Feature1\"] = df.GrLivArea + df.TotalBsmtSF\n",
    "    X[\"Feature2\"] = df.YearRemodAdd * df.TotalBsmtSF\n",
    "    return X\n",
    "\n",
    "def pca_components(df , features):\n",
    "    X = df.loc[: , features]\n",
    "    _ , X_pca , _ = apply_pca(X)\n",
    "    return X_pca\n",
    "\n",
    "pca_features = [\n",
    "    \"GarageArea\",\n",
    "    \"YearRemodAdd\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"GrLivArea\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8b6c5",
   "metadata": {
    "papermill": {
     "duration": 0.009052,
     "end_time": "2025-11-29T18:03:47.962333",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.953281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "These are only a couple ways we could use the principal components. we could also try clustering using one or more components. One thing to note is that PCA doesn't change the distance between points -- it's just like a rotation. So clustering with the full set of components is the same as clustering with the original features. Instead, pick some subset of components, maybe those with the most variance or the highest MI scores.\n",
    "\n",
    "For further analysis, we might want to look at a correlation matrix for the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e650cb58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:47.982834Z",
     "iopub.status.busy": "2025-11-29T18:03:47.982186Z",
     "iopub.status.idle": "2025-11-29T18:03:47.986971Z",
     "shell.execute_reply": "2025-11-29T18:03:47.986095Z"
    },
    "papermill": {
     "duration": 0.017234,
     "end_time": "2025-11-29T18:03:47.988953",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.971719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def corrplot(df , method=\"pearson\" , annot=True , **kwargs):\n",
    "    sns.clustermap(\n",
    "        df.corr(method, numeric_only = True),\n",
    "        vmin=-1.0,\n",
    "        vmax=1.0,\n",
    "        cmap=\"icefire\",\n",
    "        method=\"complete\",\n",
    "        annot=annot,\n",
    "        **kwargs,\n",
    "    )\n",
    "    \n",
    "    corrplot(df_train , annot=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095142bc",
   "metadata": {
    "papermill": {
     "duration": 0.009454,
     "end_time": "2025-11-29T18:03:48.007859",
     "exception": false,
     "start_time": "2025-11-29T18:03:47.998405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Groups of highly correlated features often yield interesting loadings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b59b34",
   "metadata": {
    "papermill": {
     "duration": 0.009053,
     "end_time": "2025-11-29T18:03:48.026175",
     "exception": false,
     "start_time": "2025-11-29T18:03:48.017122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### PCA Application - Indicate Outliers ###\n",
    "\n",
    "In Feature Engineering Course Exercise 5 (PCA), we applied PCA to determine houses that were **outliers**, that is, houses having values not well represented in the rest of the data. we saw that there was a group of houses in the `Edwards` neighborhood having a `SaleCondition` of `Partial` whose values were especially extreme.\n",
    "\n",
    "Some models can benefit from having these outliers indicated, which is what this next transform will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42200806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:48.046344Z",
     "iopub.status.busy": "2025-11-29T18:03:48.046014Z",
     "iopub.status.idle": "2025-11-29T18:03:48.050800Z",
     "shell.execute_reply": "2025-11-29T18:03:48.049656Z"
    },
    "papermill": {
     "duration": 0.017215,
     "end_time": "2025-11-29T18:03:48.052768",
     "exception": false,
     "start_time": "2025-11-29T18:03:48.035553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def indicate_outliers(df):\n",
    "    X_new = pd.DataFrame()\n",
    "    X_new[\"Outlier\"] = (df.Nieghborhood == \"Edwards\") & (df.SaleCondition == \"Partial\")\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4112f",
   "metadata": {
    "papermill": {
     "duration": 0.009712,
     "end_time": "2025-11-29T18:03:48.071945",
     "exception": false,
     "start_time": "2025-11-29T18:03:48.062233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we could also consider applying some sort of robust scaler from scikit-learn's `sklearn.preprocessing` module to the outlying values, especially those in `GrLivArea`. [Here](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html) is a tutorial illustrating some of them. Another option could be to create a feature of \"outlier scores\" using one of scikit-learn's [outlier detectors](https://scikit-learn.org/stable/modules/outlier_detection.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b4ce71",
   "metadata": {
    "papermill": {
     "duration": 0.009152,
     "end_time": "2025-11-29T18:03:48.091022",
     "exception": false,
     "start_time": "2025-11-29T18:03:48.081870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Target Encoding ##\n",
    "\n",
    "Needing a separate holdout set to create a target encoding is rather wasteful of data. In *Tutorial 6* we used 25% of our dataset just to encode a single feature, `Zipcode`. The data from the other features in that 25% we didn't get to use at all.\n",
    "\n",
    "There is, however, a way we can use target encoding without having to use held-out encoding data. It's basically the same trick used in cross-validation:\n",
    "1. Split the data into folds, each fold having two splits of the dataset.\n",
    "2. Train the encoder on one split but transform the values of the other.\n",
    "3. Repeat for all the splits.\n",
    "\n",
    "This way, training and transformation always take place on independent sets of data, just like when we use a holdout set but without any data going to waste.\n",
    "\n",
    "In the next hidden cell is a wrapper we can use with any target encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b47f1eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:48.112543Z",
     "iopub.status.busy": "2025-11-29T18:03:48.112182Z",
     "iopub.status.idle": "2025-11-29T18:03:48.120162Z",
     "shell.execute_reply": "2025-11-29T18:03:48.119226Z"
    },
    "papermill": {
     "duration": 0.020839,
     "end_time": "2025-11-29T18:03:48.122015",
     "exception": false,
     "start_time": "2025-11-29T18:03:48.101176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CrossFoldEncoder:\n",
    "    def __init__(self, encoder, **kwargs):\n",
    "        self.encoder_ = encoder\n",
    "        self.kwargs_ = kwargs  # keyword arguments for the encoder\n",
    "        self.cv_ = KFold(n_splits=5)\n",
    "\n",
    "    # Fit an encoder on one split and transform the feature on the\n",
    "    # other. Iterating over the splits in all folds gives a complete\n",
    "    # transformation. We also now have one trained encoder on each fold.\n",
    "    def fit_transform(self, X, y, cols):\n",
    "        self.fitted_encoders_ = []\n",
    "        self.cols_ = cols\n",
    "        X_encoded = []\n",
    "        for idx_encode, idx_train in self.cv_.split(X):\n",
    "            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n",
    "            fitted_encoder.fit(\n",
    "                X.iloc[idx_encode, :], y.iloc[idx_encode],\n",
    "            )\n",
    "            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n",
    "            self.fitted_encoders_.append(fitted_encoder)\n",
    "        X_encoded = pd.concat(X_encoded)\n",
    "        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n",
    "        return X_encoded\n",
    "\n",
    "    # To transform the test data, average the encodings learned from each fold.\n",
    "    \n",
    "    def transform(self, X):\n",
    "        from functools import reduce\n",
    "\n",
    "        X_encoded_list = []\n",
    "        for fitted_encoder in self.fitted_encoders_:\n",
    "            X_encoded = fitted_encoder.transform(X)\n",
    "            X_encoded_list.append(X_encoded[self.cols_])\n",
    "        X_encoded = reduce(\n",
    "            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n",
    "        ) / len(X_encoded_list)\n",
    "        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n",
    "        return X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a84de9",
   "metadata": {
    "papermill": {
     "duration": 0.009141,
     "end_time": "2025-11-29T18:03:48.140712",
     "exception": false,
     "start_time": "2025-11-29T18:03:48.131571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use it like:\n",
    "\n",
    "```\n",
    "encoder = CrossFoldEncoder(MEstimateEncoder, m=1)\n",
    "X_encoded = encoder.fit_transform(X, y, cols=[\"MSSubClass\"]))\n",
    "```\n",
    "\n",
    "we can turn any of the encoders from the [`category_encoders`](http://contrib.scikit-learn.org/category_encoders/) library into a cross-fold encoder. The [`CatBoostEncoder`](http://contrib.scikit-learn.org/category_encoders/catboost.html) would be worth trying. It's similar to `MEstimateEncoder` but uses some tricks to better prevent overfitting. Its smoothing parameter is called `a` instead of `m`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f08f0b",
   "metadata": {
    "papermill": {
     "duration": 0.009135,
     "end_time": "2025-11-29T18:03:48.160045",
     "exception": false,
     "start_time": "2025-11-29T18:03:48.150910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Final Feature Set ##\n",
    "\n",
    "Now let's combine everything together. Putting the transformations into separate functions makes it easier to experiment with various combinations. The ones I left uncommented I found gave the best results. we should experiment with our own ideas though! Modify any of these transformations or come up with some of our own to add to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d9d36fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:48.180195Z",
     "iopub.status.busy": "2025-11-29T18:03:48.179827Z",
     "iopub.status.idle": "2025-11-29T18:03:52.838610Z",
     "shell.execute_reply": "2025-11-29T18:03:52.836552Z"
    },
    "papermill": {
     "duration": 4.672386,
     "end_time": "2025-11-29T18:03:52.841738",
     "exception": false,
     "start_time": "2025-11-29T18:03:48.169352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13694237566469133"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_features(df, df_test=None):\n",
    "    X = df.copy()\n",
    "    y = X.pop(\"SalePrice\")\n",
    "    mi_scores = make_mi_scores(X, y)\n",
    "\n",
    "    # Combine splits if test data is given\n",
    "    #\n",
    "    # If we're creating features for test set predictions, we should\n",
    "    # use all the data we have available. After creating our features,\n",
    "    # we'll recreate the splits.\n",
    "    if df_test is not None:\n",
    "        X_test = df_test.copy()\n",
    "        X_test.pop(\"SalePrice\")\n",
    "        X = pd.concat([X, X_test])\n",
    "\n",
    "    # Lesson 2 - Mutual Information\n",
    "    X = drop_uninformative(X, mi_scores)\n",
    "\n",
    "    # Lesson 3 - Transformations\n",
    "    X = X.join(mathematical_transforms(X))\n",
    "    X = X.join(interactions(X))\n",
    "    X = X.join(counts(X))\n",
    "    # X = X.join(break_down(X))\n",
    "    X = X.join(group_transforms(X))\n",
    "\n",
    "    # Lesson 4 - Clustering\n",
    "    # X = X.join(cluster_labels(X, cluster_features, n_clusters=20))\n",
    "    # X = X.join(cluster_distance(X, cluster_features, n_clusters=20))\n",
    "\n",
    "    # Lesson 5 - PCA\n",
    "    X = X.join(pca_inspired(X))\n",
    "    # X = X.join(pca_components(X, pca_features))\n",
    "    # X = X.join(indicate_outliers(X))\n",
    "\n",
    "    X = label_encode(X)\n",
    "\n",
    "    # Reform splits\n",
    "    if df_test is not None:\n",
    "        X_test = X.loc[df_test.index, :]\n",
    "        X.drop(df_test.index, inplace=True)\n",
    "\n",
    "    # Lesson 6 - Target Encoder\n",
    "    encoder = CrossFoldEncoder(MEstimateEncoder, m=1)\n",
    "    X = X.join(encoder.fit_transform(X, y, cols=[\"MSSubClass\"]))\n",
    "    if df_test is not None:\n",
    "        X_test = X_test.join(encoder.transform(X_test))\n",
    "\n",
    "    if df_test is not None:\n",
    "        return X, X_test\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "\n",
    "df_train, df_test = load_data()\n",
    "X_train = create_features(df_train)\n",
    "y_train = df_train.loc[:, \"SalePrice\"]\n",
    "\n",
    "score_dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a91ac5b",
   "metadata": {
    "papermill": {
     "duration": 0.012112,
     "end_time": "2025-11-29T18:03:52.869400",
     "exception": false,
     "start_time": "2025-11-29T18:03:52.857288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 4 - Hyperparameter Tuning #\n",
    "\n",
    "At this stage, we might like to do some hyperparameter tuning with XGBoost before creating our final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "150ebd2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:03:52.896482Z",
     "iopub.status.busy": "2025-11-29T18:03:52.896139Z",
     "iopub.status.idle": "2025-11-29T18:04:11.163620Z",
     "shell.execute_reply": "2025-11-29T18:04:11.162690Z"
    },
    "papermill": {
     "duration": 18.286269,
     "end_time": "2025-11-29T18:04:11.165594",
     "exception": false,
     "start_time": "2025-11-29T18:03:52.879325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12491217413174481"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = create_features(df_train)\n",
    "y_train = df_train.loc[:, \"SalePrice\"]\n",
    "\n",
    "xgb_params = dict(\n",
    "    max_depth=6,           # maximum depth of each tree - try 2 to 10\n",
    "    learning_rate=0.01,    # effect of each tree - try 0.0001 to 0.1\n",
    "    n_estimators=1000,     # number of trees (that is, boosting rounds) - try 1000 to 8000\n",
    "    min_child_weight=1,    # minimum number of houses in a leaf - try 1 to 10\n",
    "    colsample_bytree=0.7,  # fraction of features (columns) per tree - try 0.2 to 1.0\n",
    "    subsample=0.7,         # fraction of instances (rows) per tree - try 0.2 to 1.0\n",
    "    reg_alpha=0.5,         # L1 regularization (like LASSO) - try 0.0 to 10.0\n",
    "    reg_lambda=1.0,        # L2 regularization (like Ridge) - try 0.0 to 10.0\n",
    "    num_parallel_tree=1,   # set > 1 for boosted random forests\n",
    ")\n",
    "\n",
    "xgb = XGBRegressor(**xgb_params)\n",
    "score_dataset(X_train, y_train, xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30977bc",
   "metadata": {
    "papermill": {
     "duration": 0.009259,
     "end_time": "2025-11-29T18:04:11.184433",
     "exception": false,
     "start_time": "2025-11-29T18:04:11.175174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Just tuning these by hand can give wee great results. However, we might like to try using one of scikit-learn's automatic [hyperparameter tuners](https://scikit-learn.org/stable/modules/grid_search.html). Or we could explore more advanced tuning libraries like [Optuna](https://optuna.readthedocs.io/en/stable/index.html) or [scikit-optimize](https://scikit-optimize.github.io/stable/).\n",
    "\n",
    "Here is how we can use Optuna with XGBoost:\n",
    "\n",
    "```\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    xgb_params = dict(\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 1000, 8000),\n",
    "        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n",
    "        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n",
    "    )\n",
    "    xgb = XGBRegressor(**xgb_params)\n",
    "    return score_dataset(X_train, y_train, xgb)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "xgb_params = study.best_params\n",
    "```\n",
    "\n",
    "Copy this into a code cell if we'd like to use it, but be aware that it will take quite a while to run. After it's done, we might enjoy using some of [Optuna's visualizations](https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html).\n",
    "\n",
    "# Step 5 - Train Model and Create Submissions #\n",
    "\n",
    "Once we're satisfied with everything, it's time to create our final predictions! This cell will:\n",
    "- create your feature set from the original data\n",
    "- train XGBoost on the training data\n",
    "- use the trained model to make predictions from the test set\n",
    "- save the predictions to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76d3a679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:04:11.204873Z",
     "iopub.status.busy": "2025-11-29T18:04:11.204530Z",
     "iopub.status.idle": "2025-11-29T18:04:17.027624Z",
     "shell.execute_reply": "2025-11-29T18:04:17.026319Z"
    },
    "papermill": {
     "duration": 5.835848,
     "end_time": "2025-11-29T18:04:17.029815",
     "exception": false,
     "start_time": "2025-11-29T18:04:11.193967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Submission was successfully save :)\n"
     ]
    }
   ],
   "source": [
    "X_train , X_test = create_features(df_train , df_test)\n",
    "y_train = df_train.loc[: , \"SalePrice\"]\n",
    "\n",
    "xgb = XGBRegressor(**xgb_params)\n",
    "# XGB minimizes MSE, but competition loss is RMSLE\n",
    "# So, we need to log-transform y to train and exp-transform the predictions\n",
    "xgb.fit(X_train , np.log(y))\n",
    "predictions = np.exp(xgb.predict(X_test))\n",
    "\n",
    "output = pd.DataFrame({'Id': X_test.index , 'SalePrice': predictions})\n",
    "output.to_csv('my_submittion.csv', index=False)\n",
    "print(\"The Submission was successfully save :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c344d",
   "metadata": {
    "papermill": {
     "duration": 0.009473,
     "end_time": "2025-11-29T18:04:17.049044",
     "exception": false,
     "start_time": "2025-11-29T18:04:17.039571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 47.141425,
   "end_time": "2025-11-29T18:04:17.678189",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-29T18:03:30.536764",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
